{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries #\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import percentile\n",
    "import math\n",
    "import datetime\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from functools import reduce\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV_Formatter prepares a dataframe of values and a dataframe of percentages for each date of the fund's history. \n",
    "# It cleans the csv by isolating one measurement per day, at the Close of business, and then creating\n",
    "# a shifted column for comparison and creating a column of the daily percent change in value. \n",
    "# Both daily value and percent change are retained in two separate dataframes. \n",
    "\n",
    "def CSV_Formatter (folder_name, filename):\n",
    "    df_init = pd.read_csv('Downloads/' + str(folder_name) +'/' + str(filename) +'.csv')\n",
    "    df = df_init.set_index('Date')[['Close']]\n",
    "    df.columns = [str(filename)]\n",
    "    df['Next Day Values'] = df[filename].shift(-1)\n",
    "    df['Percentages'] = df['Next Day Values']/df[str(filename)]\n",
    "    df_final = df[['Percentages']]\n",
    "    df_final.columns = [str(filename)]\n",
    "    return(df[[filename]], df_final)\n",
    "\n",
    "# The last function is a weekly master function which collects the percent changes week to week for a domain dataframe\n",
    "# Domain dataframe should consist only of a date time index and a value series\n",
    "\n",
    "def weekly_master(df):\n",
    "    \n",
    "# A little setup is necessary to ensure fidelity across weekly data.  In the original yahoo finance data downloads,\n",
    "# Weekends and holidays are not counted in the Datetime Index.  The following code creates a working df that\n",
    "# Can be broken into calendar weeks at regular 7 day intervals, to better reflect paycheck contributions and \n",
    "# subsequent analyses can be done on a week to week basis.\n",
    "\n",
    "# Note that for days where data is unavailable, I've filled in the value 1, since the method of assessing portfolios\n",
    "# Is multiplication across daily percentage changes.  In this way, days when no percent changes are documented do not\n",
    "# affect the value of the investment.\n",
    "\n",
    "    # NOTE THAT THIS FUNCTION WILL ONLY ACCOMODATE DATAFRAMES WITH UP TO 8 COLUMNS AS WRITTEN! #\n",
    "\n",
    "    datelist = pd.to_datetime(df.index.values)\n",
    "    df['Datetime'] = datelist\n",
    "    df_timed = df.set_index('Datetime')\n",
    "    labels = df_timed.columns\n",
    "\n",
    "    df_segmented = pd.DataFrame(columns = labels)\n",
    "\n",
    "    daterange = int(str(df_timed.index.max() - df_timed.index.min()).replace(\" days 00:00:00\", ''))\n",
    "    all_dates = pd.date_range(df_timed.index.min(), periods=daterange).tolist()\n",
    "    \n",
    "    index_df = pd.DataFrame(all_dates)\n",
    "    index_df.columns = ['Datetime']\n",
    "    \n",
    "    working_df = index_df.merge(df_timed, how = 'outer', left_on = 'Datetime', right_on ='Datetime')\n",
    "    working_df = working_df.fillna(1).set_index('Datetime').sort_values('Datetime', ascending = False)\n",
    "\n",
    "    days = len(working_df.index)\n",
    "    number_of_weeks = int(np.floor(days/7))\n",
    "\n",
    "    df_progress = pd.DataFrame(index=[0,1,2,3,4])\n",
    "    weekly_eval = pd.DataFrame()\n",
    "\n",
    "    for i in range(0, number_of_weeks):\n",
    "        portfolio_segment = working_df.iloc[i*7:(i+1)*7]\n",
    "        \n",
    "        products =[]\n",
    "        prod_1 = portfolio_segment.iloc[:, 0].product()\n",
    "        products.append(prod_1)\n",
    "\n",
    "        if len(labels) > 1:\n",
    "            prod_2 = portfolio_segment.iloc[:, 1].product()\n",
    "            products.append(prod_2)\n",
    "        if len(labels) > 2:        \n",
    "            prod_3 = portfolio_segment.iloc[:, 2].product()\n",
    "            products.append(prod_3)\n",
    "        if len(labels) > 3:\n",
    "            prod_4 = portfolio_segment.iloc[:, 3].product()\n",
    "            products.append(prod_4)\n",
    "        if len(labels) > 4:\n",
    "            prod_5 = portfolio_segment.iloc[:, 4].product()\n",
    "            products.append(prod_5)\n",
    "        if len(labels) > 5:\n",
    "            prod_6 = portfolio_segment.iloc[:, 5].product()\n",
    "            products.append(prod_6)\n",
    "        if len(labels) > 6:\n",
    "            prod_7 = portfolio_segment.iloc[:, 6].product()\n",
    "            products.append(prod_7)\n",
    "        if len(labels) > 7:\n",
    "            prod_8 = portfolio_segment.iloc[:, 7].product()\n",
    "            products.append(prod_8)\n",
    "   \n",
    "    # Can we just make this into a loop?\n",
    "    #    For j in range(0, len(labels)):\n",
    "    #        temp_prod = portfolio_segment.iloc[:, j].product()\n",
    "    #        products.append(temp_prod)\n",
    "\n",
    "\n",
    "        weekly_eval[str(portfolio_segment.index[7-1]).replace(\"00:00:00\", '')] = products\n",
    "    \n",
    "    weekly_eval = weekly_eval.T\n",
    "    weekly_eval.columns = labels\n",
    "    weekly_eval.index = pd.to_datetime(weekly_eval.index)\n",
    "    weekly_eval.index.name = 'Date'\n",
    "    weekly_eval.sort_index()\n",
    "\n",
    "    return(weekly_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Cell reads all necessary source files for STOCK INDICES #\n",
    "\n",
    "(PREIX, PREIX_final) = CSV_Formatter('Stock_Indices', 'PREIX')\n",
    "(FUSEX, FUSEX_final) = CSV_Formatter('Stock_Indices', 'FUSEX')\n",
    "(SWPPX, SWPPX_final) = CSV_Formatter('Stock_Indices', 'SWPPX')\n",
    "(VFINX, VFINX_final) = CSV_Formatter('Stock_Indices', 'VFINX')\n",
    "(VIGRX, VIGRX_final) = CSV_Formatter('Stock_Indices', 'VIGRX')\n",
    "\n",
    "# Creates dataframes of their daily values and daily percent changes , aka increments.\n",
    "dfstock_values = [PREIX[['PREIX']], FUSEX[['FUSEX']], SWPPX[['SWPPX']], VFINX[['VFINX']], VIGRX[['VIGRX']]]\n",
    "dfstock_finals = [PREIX_final, FUSEX_final, SWPPX_final, VFINX_final, VIGRX_final]\n",
    "stock_daily_values_df = reduce(lambda left, right: pd.merge(left, right, on = 'Date'), dfstock_values)\n",
    "stock_increments_df = reduce(lambda left, right: pd.merge(left, right, on = 'Date'), dfstock_finals)\n",
    "\n",
    "stock_weekly = weekly_master(stock_increments_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Cell reads all necessary source files for Intermediate Term Bonds #\n",
    "\n",
    "(BIV, BIV_final) = CSV_Formatter('Intermediate_Bonds', 'BIV')\n",
    "(HYG, HYG_final) = CSV_Formatter('Intermediate_Bonds', 'HYG')\n",
    "(IEF, IEF_final) = CSV_Formatter('Intermediate_Bonds', 'IEF')\n",
    "(IEI, IEI_final) = CSV_Formatter('Intermediate_Bonds', 'IEI')\n",
    "(IGIB, IGIB_final) = CSV_Formatter('Intermediate_Bonds', 'IGIB')\n",
    "(IPE, IPE_final) = CSV_Formatter('Intermediate_Bonds', 'IPE')\n",
    "(ITE, ITE_final) = CSV_Formatter('Intermediate_Bonds', 'ITE')\n",
    "(TIP, TIP_final) = CSV_Formatter('Intermediate_Bonds', 'TIP')\n",
    "\n",
    "# Creates dataframes of their daily values and daily percent changes , aka increments.\n",
    "df_itb_values = [BIV[['BIV']], HYG[['HYG']], IEF[['IEF']], IEI[['IEI']], IGIB[['IGIB']], IPE[['IPE']], ITE[['ITE']], TIP[['TIP']]]\n",
    "df_itb_finals = [BIV_final, HYG_final, IEF_final, IEI_final, IGIB_final, IPE_final, ITE_final, TIP_final]\n",
    "itb_daily_values_df = reduce(lambda left, right: pd.merge(left, right, on = 'Date'), df_itb_values)\n",
    "itb_increments_df = reduce(lambda left, right: pd.merge(left, right, on = 'Date'), df_itb_finals)\n",
    "\n",
    "itb_weekly = weekly_master(itb_increments_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Cell reads all necessary source files for Long Term Bonds #\n",
    "\n",
    "(PRULX, PRULX_final) = CSV_Formatter('Long_Term_Bonds', 'PRULX')\n",
    "(VUSTX, VUSTX_final) = CSV_Formatter('Long_Term_Bonds', 'VUSTX')\n",
    "(WHOSX, WHOSX_final) = CSV_Formatter('Long_Term_Bonds', 'WHOSX')\n",
    "\n",
    "# Creates dataframes of their daily values and daily percent changes , aka increments.\n",
    "df_ltb_values = [PRULX[['PRULX']], VUSTX[['VUSTX']], WHOSX[['WHOSX']]]\n",
    "df_ltb_finals = [PRULX_final, VUSTX_final, WHOSX_final]\n",
    "ltb_daily_values_df = reduce(lambda left, right: pd.merge(left, right, on = 'Date'), df_ltb_values)\n",
    "ltb_increments_df = reduce(lambda left, right: pd.merge(left, right, on = 'Date'), df_ltb_finals)\n",
    "\n",
    "ltb_weekly = weekly_master(ltb_increments_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Cell reads all necessary source files for Gold \n",
    "\n",
    "(INIVX, INIVX_final) = CSV_Formatter('Gold', 'INIVX')\n",
    "(OPGSX, OPGSX_final) = CSV_Formatter('Gold', 'OPGSX')\n",
    "(SGGDX, SGGDX_final) = CSV_Formatter('Gold', 'SGGDX')\n",
    "(USERX, USERX_final) = CSV_Formatter('Gold', 'USERX')\n",
    "(VGPMX, VGPMX_final) = CSV_Formatter('Gold', 'VGPMX')\n",
    "\n",
    "# Creates dataframes of their daily values and daily percent changes , aka increments.\n",
    "dfgold_values = [INIVX[['INIVX']], OPGSX[['OPGSX']], SGGDX[['SGGDX']], USERX[['USERX']], VGPMX[['VGPMX']]]\n",
    "dfgold_finals = [INIVX_final, OPGSX_final, SGGDX_final, USERX_final, VGPMX_final]\n",
    "gold_daily_values_df = reduce(lambda left, right: pd.merge(left, right, on = 'Date'), dfgold_values)\n",
    "gold_increments_df = reduce(lambda left, right: pd.merge(left, right, on = 'Date'), dfgold_finals)\n",
    "\n",
    "gold_weekly = weekly_master(gold_increments_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Cell reads all necessary source files from their respective download folders for Broad Basket Commodities #\n",
    "\n",
    "(DBC, DBC_final) = CSV_Formatter('Broad_Commodities', 'DBC')\n",
    "(DJP, DJP_final) = CSV_Formatter('Broad_Commodities', 'DJP')\n",
    "(GSG, GSG_final) = CSV_Formatter('Broad_Commodities', 'GSG')\n",
    "(GSP, GSP_final) = CSV_Formatter('Broad_Commodities', 'GSP')\n",
    "\n",
    "# Creates dataframes of their daily values and daily percent changes , aka increments.\n",
    "df_commod_values = [DBC[['DBC']], DJP[['DJP']], GSG[['GSG']], GSP[['GSP']]]\n",
    "df_commod_finals = [DBC_final, DJP_final, GSG_final, GSP_final]\n",
    "commod_daily_values_df = reduce(lambda left, right: pd.merge(left, right, on = 'Date'), df_commod_values)\n",
    "commod_increments_df = reduce(lambda left, right: pd.merge(left, right, on = 'Date'), df_commod_finals)\n",
    "\n",
    "commod_weekly = weekly_master(commod_increments_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell creates a function to randomly select the funds in the initial portfolio #\n",
    "\n",
    "def random_all_weather(stock, inter_bond, long_bond, gold, commod):\n",
    "    \n",
    "    # First, select a fund from each investment category\n",
    "    stock_choice = stock.sample(axis=1).columns\n",
    "    inter_choice = inter_bond.sample(axis=1).columns\n",
    "    long_bond_choice = long_bond.sample(axis=1).columns\n",
    "    gold_choice = gold.sample(axis=1).columns\n",
    "    commod_choice = commod.sample(axis=1).columns\n",
    "    \n",
    "    # Extract the columns of percent changes from the df\n",
    "    rand_stock_inc = stock_weekly[stock_choice]\n",
    "    rand_inter_bond_inc = itb_weekly[inter_choice]\n",
    "    rand_long_bond_inc = ltb_weekly[long_bond_choice]\n",
    "    rand_gold_inc = gold_weekly[gold_choice]\n",
    "    rand_commod_inc = commod_weekly[commod_choice]\n",
    "\n",
    "    random_inc = rand_stock_inc.merge(\n",
    "        rand_inter_bond_inc, on = 'Date').merge(\n",
    "        rand_long_bond_inc, on = 'Date').merge(\n",
    "        rand_gold_inc, on = 'Date').merge(\n",
    "        rand_commod_inc, on = 'Date')\n",
    "    \n",
    "    # Return a portfolio of randomly sampled funds, one in each category, starting at the first date all 5 had value.\n",
    "    # Please note that the .dropna() here will restrict the amount of historical data leveraged in each portfolio.\n",
    "    portfolio = random_inc.dropna()\n",
    "    \n",
    "    return portfolio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PREIX</th>\n",
       "      <th>IPE</th>\n",
       "      <th>VUSTX</th>\n",
       "      <th>USERX</th>\n",
       "      <th>DBC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-10-06</th>\n",
       "      <td>0.959690</td>\n",
       "      <td>1.002046</td>\n",
       "      <td>1.014545</td>\n",
       "      <td>1.037538</td>\n",
       "      <td>0.980274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-29</th>\n",
       "      <td>0.986616</td>\n",
       "      <td>0.991152</td>\n",
       "      <td>0.970018</td>\n",
       "      <td>1.016794</td>\n",
       "      <td>0.996723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-22</th>\n",
       "      <td>0.997584</td>\n",
       "      <td>0.996876</td>\n",
       "      <td>0.996485</td>\n",
       "      <td>0.982009</td>\n",
       "      <td>1.031549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-15</th>\n",
       "      <td>1.010667</td>\n",
       "      <td>0.997434</td>\n",
       "      <td>0.984429</td>\n",
       "      <td>1.015221</td>\n",
       "      <td>1.033178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-08</th>\n",
       "      <td>1.004518</td>\n",
       "      <td>0.995620</td>\n",
       "      <td>0.992275</td>\n",
       "      <td>1.036278</td>\n",
       "      <td>0.998257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               PREIX       IPE     VUSTX     USERX       DBC\n",
       "Date                                                        \n",
       "2018-10-06  0.959690  1.002046  1.014545  1.037538  0.980274\n",
       "2018-09-29  0.986616  0.991152  0.970018  1.016794  0.996723\n",
       "2018-09-22  0.997584  0.996876  0.996485  0.982009  1.031549\n",
       "2018-09-15  1.010667  0.997434  0.984429  1.015221  1.033178\n",
       "2018-09-08  1.004518  0.995620  0.992275  1.036278  0.998257"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is just a test of the random portfolio generating function.\n",
    "\n",
    "test_random_portfolio = random_all_weather(stock_daily_values_df, \n",
    "                   itb_daily_values_df, \n",
    "                   ltb_daily_values_df, \n",
    "                   gold_daily_values_df, \n",
    "                   commod_daily_values_df)\n",
    "\n",
    "\n",
    "test_random_portfolio.head()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
